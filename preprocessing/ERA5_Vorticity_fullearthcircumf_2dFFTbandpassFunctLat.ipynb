{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c46ced-1d8b-4dba-900c-956a44a71439",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import metpy\n",
    "import sys\n",
    "import pandas as pd\n",
    "import netCDF4 as nc\n",
    "from os import walk\n",
    "import os\n",
    "import metpy.calc as mpcalc\n",
    "from metpy.units import units\n",
    "#from mpl_toolkits.basemap import Basemap\n",
    "import cartopy.crs as ccrs\n",
    "#import gcm_filters\n",
    "import copy\n",
    "import datetime\n",
    "import calendar\n",
    "from windspharm.standard import VectorWind\n",
    "import math\n",
    "from scipy import ndimage\n",
    "from scipy import fft\n",
    "\n",
    "\n",
    "\n",
    "def wn_filter_3d(y, kmin, kmax):\n",
    "    ############################################################################################################################\n",
    "    # - Wavenumber restriction: Take a 3-D function and return it restricted to the (kmin,kmax) wavenumber range. \n",
    "    # Author: Sandro W. Lubis (Mar 2023, PNNL)\n",
    "    ############################################################################################################################\n",
    "    # - INPUT:\n",
    "    # * y: variable with (time,lat,lon) dimensions\n",
    "    # * kmin, kmax: wavenumber range\n",
    "    ###########################################################################################################################\n",
    "    ffty = fft.fft(y.values,axis=-1)\n",
    "    mask = np.zeros((ffty.shape))\n",
    "    mask[:,:,kmin:kmax+1] = 1 # Keep certain freqs only. Values outside the selected range remain zero. \n",
    "    mafft = ffty*mask\n",
    "    fedit = fft.ifft(mafft)\n",
    "    fedit = 2*fedit.real # Since the ignored negative frequencies would contribute the same as the positive ones.\n",
    "    #  the DC component of the signal is unique and should not be multiplied by 2:\n",
    "    if kmin == 0:\n",
    "        fedit = fedit - ffty.real[0]/(ffty.shape[-1]) # Subtract the pre-edited function's mean. We don't want a double contribution from it in fedit (as was demanded by fedit=2*fedit.real).\n",
    "    elif kmin > 0:\n",
    "        fedit = fedit + ffty.real[0]/(ffty.shape[-1])  # Add the pre-edited function's mean. The zero frequency in FFT should never be left out when editing a function. \n",
    "    fedit = y.copy(data=fedit,deep=False)\n",
    "    return fedit\n",
    "\n",
    "\n",
    "def wn_range(LAT,wavelength):\n",
    "    #calculates a kmin and kmax to pass into wn_filter_3d\n",
    "    ###### input\n",
    "    #lat in degrees \n",
    "    #wavelength (full wavelength panning max and min) - in KILOMETERS\n",
    "    \n",
    "    Rearth = 6378  # earth radius in km\n",
    "    ktarget = ( 2 * math.pi * Rearth * math.cos( (math.pi/180)* LAT ) ) / wavelength\n",
    "    return ktarget\n",
    "\n",
    "########################################################################\n",
    "# directories containing 3D and 2D ERA5 reanalysis files: \n",
    "########################################################################\n",
    "\n",
    "#2d era5 analysis file locations:\n",
    "root2Dvars = '/<YOUR DIRECTORY HERE>/'\n",
    "root2Dvint = '/<YOUR DIRECTORY HERE>/'\n",
    "\n",
    "#3d era5 analysis file locations: \n",
    "root3Dvars = '/<YOUR DIRECTORY HERE>/'\n",
    "rootPVdir = '/<YOUR DIRECTORY HERE>/'\n",
    "\n",
    "# output directory and filenames:\n",
    "fileout = '/<YOUR DIRECTORY HERE>/ERA5_bandpass_wl' + str(WL_min) + 'to' + str(WL_max) +'km_perlat_vort_sf_b'\n",
    "            \n",
    "\n",
    "WL_min = 500   #shortest desired post-fft-filter wavelength (km)\n",
    "WL_max = 2500  #longest desired post-fft-filter wavelength (km)\n",
    "\n",
    "\n",
    "########################################################################\n",
    "# list of all YYYYMM dirs for which there are 2D and 3D ERA5 files on nersc (separetely), \n",
    "# then find common dates\n",
    "########################################################################\n",
    "\n",
    "\n",
    "# find all ERA5 data months that we have files for in root2Dvars (months_var2d):\n",
    "months_var2d = []\n",
    "for (dirpath, dirnames, filenames) in walk(root2Dvars):\n",
    "    months_var2d.extend(dirnames)\n",
    "    break\n",
    "months_var2d = [int(x) for x in months_var2d]\n",
    "months_var2d.sort()\n",
    "\n",
    "\n",
    "# find all ERA5 data months that we have files for in root3Dvars (dates_var3d):\n",
    "months_var3d = []\n",
    "for (dirpath, dirnames, filenames) in walk(root3Dvars):\n",
    "    months_var3d.extend(dirnames)\n",
    "    break\n",
    "months_var3d = [int(x) for x in months_var3d]\n",
    "months_var3d.sort()\n",
    "\n",
    "\n",
    "# find common dates among the 2D and 3D variable list (commondates):   \n",
    "list1_as_set = set(months_var2d)\n",
    "intersection = list1_as_set.intersection(months_var3d)\n",
    "commonmonths = list(intersection)\n",
    "commonmonths.sort()\n",
    "\n",
    "# Convert common to Year-Month strings for future use (YYYYMM):  \n",
    "YYYYMM = []\n",
    "for t in commonmonths:\n",
    "    yyyy = str(t)[0:4]\n",
    "    mm = str(t)[4:6]\n",
    "    YYYYMM.append(yyyy + '-' + mm)\n",
    "    \n",
    "  \n",
    "    \n",
    "#########################################################################################################\n",
    "# generate file lists of the variables that we want from the list of common months   \n",
    "#########################################################################################################\n",
    "\n",
    "# list of all 2D-metric files of a particular variable (e.g., tcwv) in the whole climo period (PWfiles):  \n",
    "PWfiles = []\n",
    "for date in commonmonths:\n",
    "    pwdatepath = root2Dvars + str(date)+ \"/\"\n",
    "    # print(pwdatepath)\n",
    "    for r, d, f in walk(pwdatepath):\n",
    "        for file in f:\n",
    "            if 'tcwv' in file:\n",
    "                PWfiles.append(os.path.join(r,file))\n",
    "                \n",
    "VIWVDfiles = []\n",
    "for date in commonmonths:\n",
    "    viwvddatepath = root2Dvint + str(date)+ \"/\"\n",
    "    # print(pwdatepath)\n",
    "    for r, d, f in walk(viwvddatepath):\n",
    "        for file in f:\n",
    "            if 'viwvd' in file:\n",
    "                VIWVDfiles.append(os.path.join(r,file))  \n",
    "        \n",
    "CAPEfiles = []\n",
    "for date in commonmonths:\n",
    "    capedatepath = root2Dvars + str(date)+ \"/\"\n",
    "    # print(pwdatepath)\n",
    "    for r, d, f in walk(capedatepath):\n",
    "        for file in f:\n",
    "            if 'cape' in file:\n",
    "                CAPEfiles.append(os.path.join(r,file))        \n",
    "                \n",
    "SPfiles = []\n",
    "for date in commonmonths:\n",
    "    spdatepath = root2Dvars + str(date)+ \"/\"\n",
    "    # print(pwdatepath)\n",
    "    for r, d, f in walk(spdatepath):\n",
    "        for file in f:\n",
    "            if '_sp.' in file:\n",
    "                SPfiles.append(os.path.join(r,file))\n",
    " \n",
    "\n",
    "                 \n",
    "    \n",
    "# list of all files of a prescribed 3D <variable> in the whole climo period (<VAR>files):  \n",
    "Ufiles = []\n",
    "Vfiles = []\n",
    "Wfiles = []\n",
    "QVfiles = []\n",
    "RHfiles = []\n",
    "Zfiles = []\n",
    "Tfiles = []\n",
    "for date in commonmonths:\n",
    "    datepath = root3Dvars + str(date)+ \"/\"\n",
    "    for r, d, f in walk(datepath):\n",
    "        for file in f:\n",
    "            if '_u.' in file:\n",
    "                Ufiles.append(os.path.join(r,file))    \n",
    "            if '_v.' in file:\n",
    "                Vfiles.append(os.path.join(r,file)) \n",
    "            if '_w.' in file:\n",
    "                Wfiles.append(os.path.join(r,file))\n",
    "            if '_q.' in file:\n",
    "                QVfiles.append(os.path.join(r,file)) \n",
    "            if '_r.' in file:\n",
    "                RHfiles.append(os.path.join(r,file))  \n",
    "            if '_t.' in file:\n",
    "                Tfiles.append(os.path.join(r,file))          \n",
    "            if '_z.' in file:\n",
    "                Zfiles.append(os.path.join(r,file))\n",
    "#sort them alpha-numerically:\n",
    "Ufiles.sort()\n",
    "Vfiles.sort()\n",
    "Wfiles.sort()\n",
    "QVfiles.sort()\n",
    "RHfiles.sort()    \n",
    "PWfiles.sort()\n",
    "Tfiles.sort()\n",
    "Zfiles.sort()\n",
    "CAPEfiles.sort()\n",
    "VIWVDfiles.sort()\n",
    "\n",
    "\n",
    "# list of all files of a prescribed 3D <variable> in the whole climo period (<VAR>files):  \n",
    "PVfiles = []\n",
    "for date in commonmonths:\n",
    "    datepath = rootPVdir + str(date)+ \"/\"\n",
    "    for r, d, f in walk(datepath):\n",
    "        for file in f:\n",
    "            if '_pv.' in file:\n",
    "                PVfiles.append(os.path.join(r,file))\n",
    "#sort them alpha-numerically:\n",
    "PVfiles.sort()\n",
    "\n",
    "\n",
    "# get days in addition to the months (YYYYMMDD_var3d). \n",
    "# I'm using the U variable as an example and ASSUMING THAT IF THERE ARE ANY GAPS IN U, THERE ARE EQUIVALENT GAPS IN THE OTHER VARIABLES \n",
    "\n",
    "YYYYMMDD_var3d = [\"00000000\"]  \n",
    "for file in Ufiles:\n",
    "    year = str(file)[-24:-20]\n",
    "    mon = str(file)[-20:-18]\n",
    "    day = str(file)[-18:-16] \n",
    "    YYYYMMDD_var3d.append(year + mon + day)\n",
    "YYYYMMDD_var3d = YYYYMMDD_var3d[1:-1]  #chop off the vestigial 1st element.\n",
    "\n",
    "\n",
    "# get days in addition to the months (YYYYMMDD_var2d). \n",
    "# I'm using the PW variable as an example and ASSUMING THAT IF THERE ARE ANY GAPS IN U, THERE ARE EQUIVALENT GAPS IN THE OTHER VARIABLES \n",
    "\n",
    "YYYYMMDD_var2d = [\"00000000\"]  \n",
    "for file in PWfiles:\n",
    "    year = str(file)[-24:-20]\n",
    "    mon = str(file)[-20:-18]\n",
    "    day = str(file)[-18:-16] \n",
    "    YYYYMMDD_var2d.append(year +  mon +  day)\n",
    "YYYYMMDD_var2d = YYYYMMDD_var2d[1:-1] #chop off the vestigial 1st element.\n",
    "\n",
    "days = YYYYMMDD_var3d\n",
    "\n",
    "#print(days)\n",
    "\n",
    "################################################################################\n",
    "# loop thru each month label and find the 3D files that match that month:\n",
    "################################################################################\n",
    "\n",
    "\n",
    "#lat/lon bounds of sub-global domain: \n",
    "#note: .sel wasn't working properly on ERA5 data when lat1 < lat2. So, this results in -dy later, though proper sign of vertical voriticity, interstingly. I will correct\n",
    "#the sign on dy later. \n",
    "lat1 = 70          #70  #67 #57.\n",
    "lat2 = 10        #10 #20.\n",
    "lon1 = 0 #10       #190 #0 190 #200.\n",
    "lon2 = 360       #290 #360 294 #284.\n",
    "\n",
    "\n",
    "\n",
    "#need to define a dummy array to concat things into:\n",
    "era5fileU = xr.open_dataset(Ufiles[0])\n",
    "dummy2dt = era5fileU.U.sel(longitude = slice(lon1,lon2), latitude  = slice(lat1,lat2)) #* units('m/s')\n",
    "ddum,cdum,adum,bdum = dummy2dt.shape\n",
    "\n",
    "ZS = range(cdum)\n",
    "YS = range(adum)\n",
    "XS = range(bdum)\n",
    "TS = range(ddum)\n",
    "\n",
    "#print(\"a,b 1\",a,b)\n",
    "\n",
    "longitude = copy.deepcopy(era5fileU.longitude)\n",
    "latitude = copy.deepcopy(era5fileU.latitude)\n",
    "longitude = longitude.sel(longitude = slice(lon1,lon2))\n",
    "latitude = latitude.sel(latitude  = slice(lat1,lat2))\n",
    "level = copy.deepcopy(era5fileU.level)\n",
    "dx, dy = mpcalc.lat_lon_grid_deltas(longitude, latitude)\n",
    "\n",
    "#### seed blank (x,y,t) arrays:\n",
    "#times = np.array([], dtype='datetime64[ns]').reshape(0)\n",
    "##basetime = np.array([], dtype=np.int64).reshape(0) \n",
    "\n",
    "\n",
    "######################################################################\n",
    "# loop through dates to generate raw desired variables per day: \n",
    "######################################################################\n",
    "\n",
    "##manually define target processing months (in commonmonths index space) I care about coresponding to the MCS climo - manual because python makes no sense:\n",
    "#mjjas_2000thru2012 = [4,5,6,7,8,  16,17,18,19,20,  28,29,30,31,32,  40,41,42,43,44,   52,53,54,55,56,   64,65,66,67,68,   76,77,78,79,80, \\\n",
    "#                     88,89,90,91,92,  100,101,102,103,104,  112,113,114,115,116,   124,125,126,127,128,   136,137,138,139,140,    148,149,150,151,152]\n",
    "\n",
    "#mjja_2000thru2012 = [4,5,6,7,  16,17,18,19,  28,29,30,31,  40,41,42,43,   52,53,54,55,   64,65,66,67,   76,77,78,79, \\\n",
    "#                     88,89,90,91,  100,101,102,103,  112,113,114,115,   124,125,126,127,   136,137,138,139,    148,149,150,151]\n",
    "\n",
    "#mjjas_2011thru2012 = [136,137,138,139,140,    148,149,150,151,152]\n",
    "#mjja_2012 = [148,149,150,151]\n",
    "#mjja_2011 = [136,137,138,139]\n",
    "#mjja_2009thru2010 = [112,113,114,115,   124,125,126,127]\n",
    "#mjja_2006thru2008 = [76,77,78,79, 88,89,90,91,  100,101,102,103]\n",
    "#mjja_2004thru2005 = [52,53,54,55,56,   64,65,66,67,68]\n",
    "#mjjas_2011thru2012 = [136,137,138,139,140,    148,149,150,151,152]\n",
    "#mjjas_2010thru2011 = [124,125,126,127,   136,137,138,139]\n",
    "\n",
    "\n",
    "#mjja_2000thru2009 = [4,5,6,7,  16,17,18,19,  28,29,30,31,  40,41,42,43,   52,53,54,55,   64,65,66,67,   76,77,78,79, \\\n",
    "                     88,89,90,91,  100,101,102,103,  112,113,114,115]\n",
    "\n",
    "#mjja_2016thru2021 = [196,197,198,199,  208,209,210,211,  220,221,222,223,  232,233,234,235, 244,245,246,247, 256,257,258,259]\n",
    "\n",
    "mjja_2000thru2021 = [4,5,6,7,  16,17,18,19,  28,29,30,31,  40,41,42,43,   52,53,54,55,   64,65,66,67,   \\\n",
    "                     76,77,78,79,  88,89,90,91,  100,101,102,103,  112,113,114,115,   124,125,126,127,\\\n",
    "                     136,137,138,139,   148,149,150,151,  160,161,162,163,  172,173,174,175,  184,185,186,187,\\\n",
    "                     196,197,198,199,   208,209,210,211,  220,221,222,223,  232,233,234,235,  244,245,246,247,\\\n",
    "                     256,257,258,259]\n",
    "\n",
    "#mjja_2000thru2015 = [4,5,6,7,  16,17,18,19,  28,29,30,31,  40,41,42,43,   52,53,54,55,   64,65,66,67,   \\\n",
    "#                     76,77,78,79,  88,89,90,91,  100,101,102,103,  112,113,114,115,   124,125,126,127,\\\n",
    "#                     136,137,138,139,   148,149,150,151,  160,161,162,163,  172,173,174,175,  184,185,186,187]\n",
    "\n",
    "#mjja_2010thru2015 = [124,125,126,127,   136,137,138,139,    148,149,150,151,  160,161,162,163,  172,173,174,175,  184,185,186,187]\n",
    "#mjja_2010thru2015 = [151,  160,161,162,163,  172,173,174,175,  184,185,186,187]\n",
    "\n",
    "\n",
    "targetmonths =  mjja_2000thru2021\n",
    "\n",
    "for mm in targetmonths:    \n",
    "    mon = commonmonths[mm]\n",
    "    \n",
    "    print(\"MON in commonmonths \",mon)\n",
    "    \n",
    "    #load the monthly PW and sfc Pres files\n",
    "    for spfile in SPfiles:\n",
    "        if str(mon) in spfile:\n",
    "            era5fileSP = xr.open_dataset(spfile)  \n",
    "            spmon = era5fileSP.SP.sel(longitude = slice(lon1,lon2), latitude  = slice(lat1,lat2))     \n",
    "    \n",
    "    for pwfile in PWfiles:\n",
    "        if str(mon) in pwfile:\n",
    "            era5filePW = xr.open_dataset(pwfile)  \n",
    "            pwmon = era5filePW.TCWV.sel(longitude = slice(lon1,lon2), latitude  = slice(lat1,lat2)) \n",
    "     \n",
    "    for capefile in CAPEfiles:\n",
    "        if str(mon) in capefile:\n",
    "            era5fileCAPE = xr.open_dataset(capefile)  \n",
    "            capemon = era5fileCAPE.CAPE.sel(longitude = slice(lon1,lon2), latitude  = slice(lat1,lat2)) \n",
    "            \n",
    "    for viwvdfile in VIWVDfiles:\n",
    "        if str(mon) in viwvdfile:\n",
    "            era5fileVIWVD = xr.open_dataset(viwvdfile)  \n",
    "            viwvdmon = era5fileVIWVD.VIWVD.sel(longitude = slice(lon1,lon2), latitude  = slice(lat1,lat2))\n",
    "\n",
    "    for d in range(len(days)):\n",
    "    #for d in range(4520,4521):    #test = [148]  #4520,4536\n",
    "        \n",
    "        day = days[d]\n",
    "\n",
    "        \n",
    "        if str(mon) in str(day[0:6]):      \n",
    "            #day = days[d]\n",
    "            \n",
    "            print('days[d] ',d,' ', day)\n",
    "\n",
    "            #### seed blank (x,y,t) arrays:\n",
    "            times = np.array([], dtype='datetime64[ns]').reshape(0)\n",
    "\n",
    "            #### seed raw wind(600,300), PW, vort600, PV\n",
    "            U600   = np.array([], dtype=np.int64).reshape(0,adum,bdum)\n",
    "            V600   = np.array([], dtype=np.int64).reshape(0,adum,bdum)\n",
    "            W600   = np.array([], dtype=np.int64).reshape(0,adum,bdum)\n",
    "            PV600   = np.array([], dtype=np.int64).reshape(0,adum,bdum)\n",
    "\n",
    "            ##################################################\n",
    "            #### now start the variable writing: \n",
    "            ##################################################\n",
    "\n",
    "            #print(\" DAY \",day)\n",
    "            yyyy = day[0:4]\n",
    "            mm = day[4:6]\n",
    "            dd = day[6:8] \n",
    "            ymd = (str(yyyy) + \"-\" + str(mm) + \"-\" + str(dd) )\n",
    "\n",
    "            pwday = pwmon.sel(time = str(ymd))     \n",
    "            capeday = capemon.sel(time = str(ymd))  \n",
    "            viwvdday = viwvdmon.sel(time = str(ymd))  \n",
    "            spday = spmon.sel(time = str(ymd))\n",
    "\n",
    "        \n",
    "            \n",
    "            ############################################################################\n",
    "            # loop through files to generate raw desired variables from 3D files: \n",
    "            ############################################################################\n",
    "\n",
    "            #daily U winds\n",
    "            for ufile in Ufiles: \n",
    "                blahh = '.' + day + '00_'\n",
    "                if blahh in str(ufile):\n",
    "                    era5fileU = xr.open_dataset(ufile)   \n",
    "\n",
    "                    #u3 = era5fileU.U.sel(longitude = slice(lon1,lon2), latitude  = slice(lat1,lat2), level = 300) #* units('m/s')\n",
    "                    u6 = era5fileU.U.sel(longitude = slice(lon1,lon2), latitude  = slice(lat1,lat2), level = 600) #* units('m/s')  \n",
    "                    U600 = np.append(U600, np.atleast_3d(u6), axis = 0)\n",
    "                \n",
    "                    times = np.append(times, u6.time)\n",
    "\n",
    "                    # make array for secs since 1970 of each hour of this day:\n",
    "                    secssince1970 = 999\n",
    "                    for hr in TS:\n",
    "                        #print(hr)\n",
    "                        dd = day\n",
    "                        d=datetime.datetime(int(dd[0:4]),int(dd[4:6]),int(dd[6:8]), hr)\n",
    "                        secssince1970 = np.append(secssince1970,calendar.timegm(d.timetuple()))\n",
    "                    secssince1970 = np.delete(secssince1970,0)\n",
    "\n",
    "\n",
    "            #daily V winds:       \n",
    "            for vfile in Vfiles: \n",
    "                if blahh in str(vfile): \n",
    "                    era5fileV = xr.open_dataset(vfile)   \n",
    "                    v6 = era5fileV.V.sel(longitude = slice(lon1,lon2), latitude  = slice(lat1,lat2), level = 600) #* units('m/s')    \n",
    "                    V600 = np.append(V600, np.atleast_3d(v6), axis = 0)    \n",
    "\n",
    "                    \n",
    "            #daily W winds:       \n",
    "            for wfile in Wfiles: \n",
    "                if blahh in str(wfile): \n",
    "                    era5fileW = xr.open_dataset(wfile)   \n",
    "                    w6 = era5fileW.W.sel(longitude = slice(lon1,lon2), latitude  = slice(lat1,lat2), level = 600) #* units('m/s')    \n",
    "                    W600 = np.append(W600, np.atleast_3d(w6), axis = 0) \n",
    "                    \n",
    "                    \n",
    "            #daily PV winds:       \n",
    "            for pvfile in PVfiles: \n",
    "                if blahh in str(pvfile):\n",
    "                    era5filePV = xr.open_dataset(pvfile)   \n",
    "                    pv6 = era5filePV.PV.sel(longitude = slice(lon1,lon2), latitude  = slice(lat1,lat2), level = 600) #* units('m/s')    \n",
    "                    PV600 = np.append(PV600, np.atleast_3d(pv6), axis = 0)     \n",
    "\n",
    "\n",
    "  \n",
    "            #####################################\n",
    "            #turn them into xarray for output: \n",
    "            #####################################         \n",
    "\n",
    "            \n",
    "            # # polish up vars\n",
    "            ppw = pwday.values\n",
    "            ccape = capeday.values\n",
    "            vviwvd = viwvdday.values\n",
    "            ssp = spday.values\n",
    "            PW    = xr.DataArray(ppw, coords=[times, latitude, longitude], dims=[\"time\", \"latitude\", \"longitude\"], name = \"PW\")\n",
    "            CAPE  = xr.DataArray(ccape, coords=[times, latitude, longitude], dims=[\"time\", \"latitude\", \"longitude\"], name = \"CAPE\")\n",
    "            VIWVD = xr.DataArray(vviwvd, coords=[times, latitude, longitude], dims=[\"time\", \"latitude\", \"longitude\"], name = \"VIWVD\")\n",
    "            SP    = xr.DataArray(ssp, coords=[times, latitude, longitude], dims=[\"time\", \"latitude\", \"longitude\"], name = \"SP\")        \n",
    "         \n",
    "            U600     = xr.DataArray(U600, coords=[times, latitude, longitude], dims=[\"time\", \"latitude\", \"longitude\"],name = \"U600\")\n",
    "            V600     = xr.DataArray(V600, coords=[times, latitude, longitude], dims=[\"time\", \"latitude\", \"longitude\"],name = \"V600\")\n",
    "            W600     = xr.DataArray(W600, coords=[times, latitude, longitude], dims=[\"time\", \"latitude\", \"longitude\"],name = \"W600\") \n",
    "            PV600    = xr.DataArray(PV600, coords=[times, latitude, longitude], dims=[\"time\", \"latitude\", \"longitude\"],name = \"PV600\")\n",
    "\n",
    "            U600_bpf = copy.deepcopy(U600)\n",
    "            U600_bpf = U600_bpf.transpose('time','longitude','latitude')\n",
    "            V600_bpf = copy.deepcopy(V600)\n",
    "            V600_bpf = V600_bpf.transpose('time','longitude','latitude')\n",
    "            W600_bpf = copy.deepcopy(W600)\n",
    "            W600_bpf = W600_bpf.transpose('time','longitude','latitude') \n",
    "            \n",
    "            #print(CAPE)\n",
    "\n",
    "            ##############################\n",
    "            # create wavenumber filtered U & V to use throughout. \n",
    "            ##############################\n",
    "            \n",
    "\n",
    "            for ll in range(0,len(latitude)):   #lat loop\n",
    "                \n",
    "                wnmax = int( wn_range(latitude[ll],WL_min) )    #500 km  # yes, \"wnmax\" is intended to operate on \"WL_min\" (and viceversa)\n",
    "                wnmin = int( wn_range(latitude[ll],WL_max) )   #2500 km\n",
    "                \n",
    "                utest = xr.DataArray(U600[:,ll:ll+1,:], coords=[times, latitude[ll:ll+1], longitude], dims=[\"time\", \"latitude\", \"longitude\"])\n",
    "                ufilt = wn_filter_3d( utest,  wnmin,  wnmax)\n",
    "                U600_bpf[:,:,ll] = ufilt[:,0,:]\n",
    "                \n",
    "                vtest = xr.DataArray(V600[:,ll:ll+1,:], coords=[times, latitude[ll:ll+1], longitude], dims=[\"time\", \"latitude\", \"longitude\"])\n",
    "                vfilt = wn_filter_3d( vtest,  wnmin,  wnmax)\n",
    "                V600_bpf[:,:,ll] = vfilt[:,0,:]\n",
    "\n",
    "                wtest = xr.DataArray(W600[:,ll:ll+1,:], coords=[times, latitude[ll:ll+1], longitude], dims=[\"time\", \"latitude\", \"longitude\"])\n",
    "                wfilt = wn_filter_3d( wtest,  wnmin,  wnmax)\n",
    "                W600_bpf[:,:,ll] = wfilt[:,0,:]    \n",
    "                \n",
    "                \n",
    "            U600_bpf = U600_bpf.transpose('time','latitude','longitude')                \n",
    "            V600_bpf = V600_bpf.transpose('time','latitude','longitude')   \n",
    "            W600_bpf = W600_bpf.transpose('time','latitude','longitude') \n",
    "            \n",
    "            U600_bpf = xr.DataArray(U600_bpf, coords=[times, latitude, longitude], dims=[\"time\", \"latitude\", \"longitude\"],name = \"U600_bpf\")\n",
    "            V600_bpf = xr.DataArray(V600_bpf, coords=[times, latitude, longitude], dims=[\"time\", \"latitude\", \"longitude\"],name = \"V600_bpf\")   \n",
    "            W600_bpf = xr.DataArray(W600_bpf, coords=[times, latitude, longitude], dims=[\"time\", \"latitude\", \"longitude\"],name = \"W600_bpf\") \n",
    "  \n",
    "\n",
    "            ############################################################\n",
    "            #### DONE READING IN 2d/3d model fields. Now calculate derivative fields\n",
    "            ############################################################\n",
    "\n",
    "            #seed blank vorticity fields\n",
    "            VOR600 = np.array([], dtype=np.int64).reshape(adum,bdum,0)  \n",
    "            VOR600_bpf = np.array([], dtype=np.int64).reshape(adum,bdum,0)\n",
    "\n",
    "            #seed blank stream function for the day\n",
    "            SF600 = np.array([], dtype=np.int64).reshape(adum,bdum,0)\n",
    "            SF600_bpf = np.array([], dtype=np.int64).reshape(adum,bdum,0)\n",
    "            SFp600 = np.array([], dtype=np.int64).reshape(adum,bdum,0)\n",
    "            SFp600_bpf = np.array([], dtype=np.int64).reshape(adum,bdum,0)\n",
    "\n",
    "\n",
    "            #done grabbing the 3d variables, now processes them for this day, still in day loop:\n",
    "            ttt = [0]\n",
    "\n",
    "            for t in TS:\n",
    "\n",
    "                ttt = np.append(ttt, str(times[t]))\n",
    "\n",
    "                #calculate stream function (hourly over 3d space): \n",
    "\n",
    "                #convert to np format for windspharm use    \n",
    "                u_np600 = U600[t,:,:].to_numpy()\n",
    "                v_np600 = V600[t,:,:].to_numpy()\n",
    "                u_np600_bpf = U600_bpf[t,:,:].to_numpy()\n",
    "                v_np600_bpf = V600_bpf[t,:,:].to_numpy()\n",
    "\n",
    "                #[if you need to chop out the sub-surface, probably do it here]\n",
    "\n",
    "                ### Create an instance of the windspharm VectorWind class to do the computations.\n",
    "                wf600 = VectorWind( u_np600, v_np600, gridtype = 'regular', rsphere=6371200.0 )\n",
    "                wf600_bpf = VectorWind( u_np600_bpf, v_np600_bpf, gridtype = 'regular', rsphere=6371200.0 )\n",
    "\n",
    "                ### Call methods to compute streamfunction and relative vorticity.\n",
    "                psi6 = wf600.streamfunction()\n",
    "                vor6 = wf600.vorticity()\n",
    "                psi6_bpf = wf600_bpf.streamfunction()\n",
    "                vor6_bpf = wf600_bpf.vorticity()\n",
    "\n",
    "                SF600 = np.append(SF600, np.atleast_3d(psi6), axis = 2)   \n",
    "                VOR600 = np.append(VOR600, np.atleast_3d(vor6), axis = 2) \n",
    "                SF600_bpf = np.append(SF600_bpf, np.atleast_3d(psi6_bpf), axis = 2)   \n",
    "                VOR600_bpf = np.append(VOR600_bpf, np.atleast_3d(vor6_bpf), axis = 2)\n",
    "\n",
    "                \n",
    "            #now done with the day: \n",
    "\n",
    "            #\"correct\" dimension arrangemnt\n",
    "            SF600 = SF600.transpose((2, 0, 1))\n",
    "            VOR600 = VOR600.transpose((2, 0, 1))   \n",
    "            SF600_bpf = SF600_bpf.transpose((2, 0, 1))\n",
    "            VOR600_bpf = VOR600_bpf.transpose((2, 0, 1)) \n",
    "\n",
    "            # convert np arrays to xarrays:\n",
    "            SF600 = xr.DataArray(SF600, coords=[times, latitude, longitude], dims=[\"time\", \"latitude\", \"longitude\"],name = \"SF600\")          \n",
    "            VOR600 = xr.DataArray(VOR600, coords=[times, latitude, longitude], dims=[\"time\", \"latitude\", \"longitude\"],name = \"VOR600\")   \n",
    "            PV600 = xr.DataArray(PV600, coords=[times, latitude, longitude], dims=[\"time\", \"latitude\", \"longitude\"],name = \"PV600\")\n",
    "            SF600_bpf = xr.DataArray(SF600_bpf, coords=[times, latitude, longitude], dims=[\"time\", \"latitude\", \"longitude\"],name = \"SF600_bpf\")          \n",
    "            VOR600_bpf = xr.DataArray(VOR600_bpf, coords=[times, latitude, longitude], dims=[\"time\", \"latitude\", \"longitude\"],name = \"VOR600_bpf\") \n",
    "\n",
    "\n",
    "            #trim to subdomain:\n",
    "                                     #global lon range       #oldies\n",
    "            latA = 60       #70    #70       #70                     #70  #67 #57.\n",
    "            latB = 20       #10    #10       #10                     #10 #20.\n",
    "            lonA = 200     #190   #120        #0                      #190# 200.\n",
    "            lonB = 300      #290   #320      #360                    #290 #360 294 #284.   \n",
    "             \n",
    "            pw = PW.sel(longitude = slice(lonA,lonB), latitude  = slice(latA,latB))\n",
    "            cape = CAPE.sel(longitude = slice(lonA,lonB), latitude  = slice(latA,latB))\n",
    "            viwvd = VIWVD.sel(longitude = slice(lonA,lonB), latitude  = slice(latA,latB))\n",
    "            sp = SP.sel(longitude = slice(lonA,lonB), latitude  = slice(latA,latB))   \n",
    "            \n",
    "            u600 = U600.sel(longitude = slice(lonA,lonB), latitude  = slice(latA,latB))\n",
    "            v600 = V600.sel(longitude = slice(lonA,lonB), latitude  = slice(latA,latB))\n",
    "            w600 = W600.sel(longitude = slice(lonA,lonB), latitude  = slice(latA,latB))\n",
    "            vor600 = VOR600.sel(longitude = slice(lonA,lonB), latitude  = slice(latA,latB))\n",
    "            sf600 = SF600.sel(longitude = slice(lonA,lonB), latitude  = slice(latA,latB))   \n",
    "            pv600 = PV600.sel(longitude = slice(lonA,lonB), latitude  = slice(latA,latB))\n",
    "            \n",
    "            u600_bpf = U600_bpf.sel(longitude = slice(lonA,lonB), latitude  = slice(latA,latB))\n",
    "            v600_bpf = V600_bpf.sel(longitude = slice(lonA,lonB), latitude  = slice(latA,latB))\n",
    "            w600_bpf = W600_bpf.sel(longitude = slice(lonA,lonB), latitude  = slice(latA,latB))\n",
    "            vor600_bpf = VOR600_bpf.sel(longitude = slice(lonA,lonB), latitude  = slice(latA,latB))\n",
    "            sf600_bpf = SF600_bpf.sel(longitude = slice(lonA,lonB), latitude  = slice(latA,latB))   \n",
    "\n",
    "            PW = copy.deepcopy(pw)\n",
    "            CAPE = copy.deepcopy(cape)\n",
    "            VIWVD = copy.deepcopy(viwvd)\n",
    "            SP = copy.deepcopy(sp)\n",
    "            U600 = copy.deepcopy(u600)\n",
    "            V600 = copy.deepcopy(v600)\n",
    "            W600 = copy.deepcopy(w600)\n",
    "            VOR600 = copy.deepcopy(vor600)\n",
    "            SF600 = copy.deepcopy(sf600)               \n",
    "            PV600 = copy.deepcopy(pv600)\n",
    "  \n",
    "            U600_bpf = copy.deepcopy(u600_bpf)\n",
    "            V600_bpf = copy.deepcopy(v600_bpf)\n",
    "            W600_bpf = copy.deepcopy(w600_bpf)\n",
    "            VOR600_bpf = copy.deepcopy(vor600_bpf)\n",
    "            SF600_bpf = copy.deepcopy(sf600_bpf) \n",
    "\n",
    "            #calculate stream fucntion anomalie on the subdomain at all times: \n",
    "            psi6pert = copy.deepcopy(SF600)\n",
    "            aa,bb,cc = psi6pert.shape\n",
    "            print(aa,bb,cc)            \n",
    "            psi6pert = psi6pert.rename('SFp600')\n",
    "            psimean = xr.DataArray.mean(psi6pert,dim='longitude')\n",
    "            #print('psimean shape',psimean.shape)\n",
    "            for la in range(bb):\n",
    "                psi6pert[:,la,:] = SF600[:,la,:] - psimean[:,la]\n",
    "                psi6pert[:,la,:] = -1 * psi6pert[:,la,:]\n",
    "            SFp600 = psi6pert\n",
    "            \n",
    "            #calculate stream fucntion anomalie on the subdomain at all times: \n",
    "            psi6pert_bpf = copy.deepcopy(SF600_bpf)\n",
    "            aa,bb,cc = psi6pert_bpf.shape\n",
    "            print(aa,bb,cc)            \n",
    "            psi6pert_bpf = psi6pert_bpf.rename('SFp600_bpf')\n",
    "            psimean_bpf = xr.DataArray.mean(psi6pert_bpf,dim='longitude')\n",
    "            for la in range(bb):\n",
    "                psi6pert_bpf[:,la,:] = SF600_bpf[:,la,:] - psimean_bpf[:,la]\n",
    "                psi6pert_bpf[:,la,:] = -1 * psi6pert_bpf[:,la,:]\n",
    "            SFp600_bpf = psi6pert_bpf  \n",
    "            \n",
    "\n",
    "            ############################################\n",
    "            #  do some mild simple #-pt 2D running-mean smoothing to iron out some kinks \n",
    "            ############################################\n",
    "\n",
    "            aa,bb,cc = VOR600_bpf.shape\n",
    "            print(aa,bb,cc)\n",
    "            VOR600_bpf_sm1a = copy.deepcopy(VOR600_bpf)\n",
    "            VOR600_bpf_sm1a[:,:,:] = 0.0\n",
    "            VOR600_bpf_sm7pt = copy.deepcopy(VOR600_bpf)\n",
    "            VOR600_bpf_sm7pt[:,:,:] = 0.0\n",
    "\n",
    "\n",
    "            kernel_size1 = 7\n",
    "            # kernel_size2 = 9\n",
    "            # kernel_size3 = 13\n",
    "            # kernel_size4 = 21\n",
    "\n",
    "            for a in range(0,aa):       #time\n",
    "                for b in range(0,bb):   #lat\n",
    "                    #for c in range( 0+kernel_size2, cc-kernel_size2):   #lon\n",
    "                    VOR600_bpf_sm1a[a,b,:] = np.convolve(VOR600_bpf[a,b,:], np.ones(kernel_size1) / kernel_size1, mode='same')\n",
    "\n",
    "            for a in range(0,aa):       #time\n",
    "                for c in range(0,cc):   #lat\n",
    "                    VOR600_bpf_sm7pt[a,:,c] = np.convolve(VOR600_bpf_sm1a[a,:,c], np.ones(kernel_size1) / kernel_size1, mode='same')\n",
    "\n",
    "            VOR600_bpf_sm7pt = xr.DataArray(VOR600_bpf_sm7pt, coords=[VOR600_bpf.time, VOR600_bpf.latitude, VOR600_bpf.longitude], dims=[\"time\", \"latitude\", \"longitude\"],name = \"VOR600_bpf_sm7pt\")     \n",
    "\n",
    "                \n",
    "                \n",
    "                \n",
    "\n",
    "            #########################################\n",
    "            #### write to netcdf output \n",
    "            #########################################\n",
    "\n",
    "            filename = str(ymd)\n",
    "\n",
    "            \n",
    "            ttt = np.delete(ttt,0)\n",
    "            ttt = xr.DataArray(ttt, coords=[times], dims=[\"time\"],name = \"Times\")\n",
    "            secssince1970 = xr.DataArray(secssince1970, coords=[times], dims=[\"time\"],name = \"basetime\")\n",
    " \n",
    "            print('writing netcdf ', filename + filename)\n",
    "\n",
    "            # write the first var:\n",
    "            PW.to_netcdf(fileout + filename + 'PertLonDom' + str(lonA) + '_' + str(lonB) + '.nc',mode='w')\n",
    "            \n",
    "            #now append more vars to file:\n",
    "            \n",
    "            #SP.to_netcdf(fileout + filename + 'PertLonDom' + str(lonA) + '_' + str(lonB) + '.nc',mode='a') \n",
    "            VIWVD.to_netcdf(fileout + filename + 'PertLonDom' + str(lonA) + '_' + str(lonB) + '.nc',mode='a')\n",
    "            CAPE.to_netcdf(fileout + filename + 'PertLonDom' + str(lonA) + '_' + str(lonB) + '.nc',mode='a')\n",
    "            \n",
    "            ttt.to_netcdf(fileout + filename + 'PertLonDom' + str(lonA) + '_' + str(lonB) + '.nc', 'a')\n",
    "            secssince1970.to_netcdf(fileout + filename + 'PertLonDom' + str(lonA) + '_' + str(lonB) + '.nc', 'a')\n",
    "            \n",
    "            U600.to_netcdf(fileout + filename + 'PertLonDom' + str(lonA) + '_' + str(lonB) + '.nc',  'a')\n",
    "            V600.to_netcdf(fileout + filename + 'PertLonDom' + str(lonA) + '_' + str(lonB) + '.nc',  'a')   \n",
    "            W600.to_netcdf(fileout + filename + 'PertLonDom' + str(lonA) + '_' + str(lonB) + '.nc',  'a')  \n",
    "            U600_bpf.to_netcdf(fileout + filename + 'PertLonDom' + str(lonA) + '_' + str(lonB) + '.nc',  'a')\n",
    "            V600_bpf.to_netcdf(fileout + filename + 'PertLonDom' + str(lonA) + '_' + str(lonB) + '.nc',  'a')  \n",
    "            W600_bpf.to_netcdf(fileout + filename + 'PertLonDom' + str(lonA) + '_' + str(lonB) + '.nc',  'a') \n",
    "            \n",
    "            VOR600.to_netcdf(fileout + filename + 'PertLonDom' + str(lonA) + '_' + str(lonB) + '.nc',  'a')          \n",
    "            #VOR600_bpf.to_netcdf(fileout + filename + 'PertLonDom' + str(lonA) + '_' + str(lonB) + '.nc',  'a')  \n",
    "            VOR600_bpf_sm7pt.to_netcdf(fileout + filename + 'PertLonDom' + str(lonA) + '_' + str(lonB) + '.nc',  'a')\n",
    "            #VOR600_bpf_sm2b.to_netcdf(fileout + filename + 'PertLonDom' + str(lonA) + '_' + str(lonB) + '.nc',  'a') \n",
    "            \n",
    "            #SFp600.to_netcdf(fileout + filename + 'PertLonDom' + str(lonA) + '_' + str(lonB) + '.nc',  'a')\n",
    "            SFp600_bpf.to_netcdf(fileout + filename + 'PertLonDom' + str(lonA) + '_' + str(lonB) + '.nc',  'a')       \n",
    "       \n",
    "            \n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JIMenv",
   "language": "python",
   "name": "jimenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
